# Model sourcing & licenses

## Sarvam 2B (Indic)
- Source: https://huggingface.co/rachittshah/sarvam-2b-v0.5-Q4_K_M-GGUF
- License: Sarvam Community (see model card)

## Qwen 2.5 3B (Controller)
- Source: https://huggingface.co/Qwen/Qwen2.5-3B-Instruct-GGUF
- License: Apache 2.0 (see model card)

## Llama 3.2 1B (fallback)
- Source: https://huggingface.co/meta-llama/Llama-3.2-1B-GGUF
- License: Llama Community

## Notes
- Use GGUF quantized Q4_K_M for 4â€“6GB VRAM.
- Do not commit large binaries; use download scripts.
