# Maha-System: Indian AI Orchestra
# Core dependencies for running on Google Colab / Low-end GPU

# LLM Inference (GGUF format support)
llama-cpp-python>=0.2.0

# API and Web Framework (optional, for deployment)
fastapi>=0.100.0
uvicorn>=0.23.0
pydantic>=2.0.0

# Model Download
huggingface_hub>=0.19.0
tqdm>=4.65.0

# Data Processing
pyyaml>=6.0
numpy>=1.24.0

# Benchmarking
datasets>=2.14.0  # For loading evaluation datasets

# LangChain/LangGraph (optional extensions)
langgraph>=0.0.20
langchain>=0.1.0

# Development
pytest>=7.4.0
black>=23.0.0

# Notes for Google Colab:
# 1. Install llama-cpp-python with CUDA:
#    !CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install llama-cpp-python
#
# 2. For CPU-only mode (slower):
#    pip install llama-cpp-python
